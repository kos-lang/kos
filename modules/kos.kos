# SPDX-License-Identifier: MIT
# Copyright (c) 2014-2023 Chris Dragan

/* @item kos lexer()
 *
 *     lexer(filename, script)
 *
 * Kos lexer generator.
 *
 * `filename` is the name of the script file, which is for informational purposes only.
 *
 * `script` is a string, buffer or generator containing Kos script to parse.
 *
 * If `script` is a generator, it must produce strings.  Each of these strings will be
 * subsequently parsed for consecutive tokens.  The occurrence of EOL characters is used
 * to signify ends of lines.  Tokens cannot span across subsequent strings.
 *
 * The Kos lexer generator yields subsequent tokens parsed from `script`.  Each produced
 * token is an object which has the following properties:
 *
 *  * `token` - string which represents the full token.
 *  * `line` - integer which is 1-based line number where the token starts.
 *  * `column` - integer which is 1-based column number where the token starts.
 *  * `type` - integer which is the token type, one of the `type_*` constants.
 *  * `keyword` - integer which is the keyword type, one of the `keyword_*` constants.
 *  * `op` - integer which is the operator type, one of the `op_*` constants.
 *  * `sep` - integer which is the separator type, one of the `sep_*` constants.
 */
public fun lexer(filename, script)
{
    const next = raw_lexer(script)

    const brackets = []

    fun save(token, sep)
    {
        brackets.push([sep, token.type])
    }

    fun throw_token(token, str)
    {
        throw "\(filename):\(token.line):\(token.column): \(str)"
    }

    for var token in next {

        switch token.sep {

            case sep_paren_open {
                save(token, sep_paren_close)
            }
            case sep_square_open {
                save(token, sep_square_close)
            }
            case sep_curly_open {
                save(token, sep_curly_close)
            }
            case sep_paren_close,
                 sep_square_close,
                 sep_curly_close {

                if ! brackets.size {
                    throw_token(token, "unexpected '\(token.token)'")
                }

                const expected_sep, open_type = brackets.pop()

                if token.sep != expected_sep {
                    var actual_expected = expected_sep
                    switch expected_sep {
                        case sep_paren_close  { actual_expected = ")" }
                        case sep_square_close { actual_expected = "]" }
                        case sep_curly_close  { actual_expected = "}" }
                    }
                    throw_token(token, "expected '\(actual_expected)'")
                }

                if open_type == token_string_open {
                    token = next(continue_string)
                    if token.type == token_string_open {
                        save(token, sep_paren_close)
                    }
                }
            }
            default {
                if token.type == token_string_open {
                    save(token, sep_paren_close)
                }
            }
        }

        yield token
    }
}
